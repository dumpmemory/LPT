{"hyper": {"model_type": "gpt2", "data_dir": "../datasets/late_prompt/few_shot/100_samples/seed-13/rte", "model_name_or_path": "gpt2_large", "output_dir": "./ckpts/gpt2_large/few_shot/generative/APPG/18/5/2/0.005/256/rte", "log_dir": "./logs/gpt2_large/few_shot/dev", "task_name": "rte", "config_name": "", "tokenizer_name": "", "cache_dir": "", "max_seq_length": 256, "debug": false, "do_train": true, "do_eval": true, "do_infer": true, "evaluate_during_training": true, "do_lower_case": true, "per_gpu_train_batch_size": 4, "per_gpu_eval_batch_size": 8, "gradient_accumulation_steps": 2, "learning_rate": 0.005, "weight_decay": 0.1, "adam_epsilon": 1e-08, "max_grad_norm": 1.0, "num_train_epochs": 84, "max_steps": 1000, "warmup_steps": 0, "warmup_rate": 0.06, "logging_steps": 100, "no_cuda": false, "overwrite_output_dir": true, "overwrite_cache": false, "not_save_model": false, "seed": 42, "fp16": false, "fp16_opt_level": "O1", "local_rank": -1, "server_ip": "", "server_port": "", "threads": 1, "template_idx": 0, "method_type": "generative", "num_prompt_tokens": 5, "add_prompt_layer": 18, "proj_down_size": 256, "generator_type": "APPG", "n_gpu": 1, "device": "cuda", "train_batch_size": 4, "eval_batch_size": 8}}
