{"hyper": {"model_type": "deberta", "data_dir": "../datasets/late_prompt/few_shot/100_samples/seed-13/rte", "model_name_or_path": "microsoft/deberta_large", "output_dir": "./ckpts/deberta_large/few_shot/None/0/20/32/0.001/0.0/256/rte", "log_dir": "./logs/deberta_large/few_shot/dev", "task_name": "rte", "config_name": "", "tokenizer_name": "", "cache_dir": "", "max_seq_length": 160, "debug": false, "do_train": true, "do_eval": true, "do_infer": true, "evaluate_during_training": true, "do_lower_case": true, "per_gpu_train_batch_size": 32, "per_gpu_eval_batch_size": 32, "gradient_accumulation_steps": 1, "learning_rate": 0.001, "num_train_epochs": 251, "max_steps": 1000, "num_prompt_tokens": 20, "add_prompt_layer": 0, "proj_down_size": 256, "generator_type": null, "initialize_from_vocab": false, "weight_decay": 0.1, "adam_epsilon": 1e-08, "max_grad_norm": 1.0, "warmup_steps": 0, "warmup_rate": 0.0, "logging_steps": 100, "save_steps": 500, "no_cuda": false, "overwrite_output_dir": true, "overwrite_cache": false, "not_save_model": false, "seed": 42, "fp16": false, "fp16_opt_level": "O1", "local_rank": -1, "server_ip": "", "server_port": "", "threads": 1, "n_gpu": 1, "device": "cuda", "output_mode": "classification", "train_batch_size": 32, "eval_batch_size": 32}}
